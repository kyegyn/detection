import random

import numpy as np
import torch
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms
from tqdm import tqdm
import os
import yaml
import time
import sys

# 1. è·å–å½“å‰è„šæœ¬çš„ç»å¯¹è·¯å¾„ (ä¾‹å¦‚: /root/.../detection/scripts/train.py)
current_path = os.path.abspath(__file__)

# 2. è·å–å½“å‰è„šæœ¬æ‰€åœ¨çš„ç›®å½• (ä¾‹å¦‚: /root/.../detection/scripts)
script_dir = os.path.dirname(current_path)

# 3. è·å–é¡¹ç›®çš„æ ¹ç›®å½•ï¼Œå³ scripts çš„ä¸Šä¸€çº§ (ä¾‹å¦‚: /root/.../detection)
project_root = os.path.dirname(script_dir)

# 4. å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ°ç³»ç»Ÿè·¯å¾„ä¸­ï¼Œè¿™æ ·å°±èƒ½æ‰¾åˆ° models äº†
if project_root not in sys.path:
    sys.path.append(project_root)

# å¯¼å…¥ä½ ä¹‹å‰å®šä¹‰çš„æ¨¡å—
from models.tsf_net import TSFNet
from data.dataset import ForensicDataset
from losses.supcon_loss import SupConLoss
from utils.fft_utils import seed_everything
from utils.metrics import BinaryMetrics
from utils.logger import ExperimentLogger


# --- 1. å®šä¹‰åœ¨å…¨å±€èŒƒå›´ ---
def worker_init_fn(worker_id):
    """
    è¿™ä¸ªå‡½æ•°å¿…é¡»å®šä¹‰åœ¨å…¨å±€ï¼ŒWindows æ‰èƒ½åºåˆ—åŒ–å®ƒã€‚
    PyTorch çš„ DataLoader ä¼šè‡ªåŠ¨å¤„ç†åŸºç¡€ç§å­ï¼Œæˆ‘ä»¬åªéœ€è¦å–å‡ºå½“å‰ worker çš„ç§å­ä¿¡æ¯å³å¯ã€‚
    """
    # è·å– PyTorch ä¸ºå½“å‰ worker åˆ†é…çš„ç§å­
    worker_seed = torch.initial_seed() % 2**32

    # è®¾ç½® Python å’Œ NumPy çš„ç§å­
    np.random.seed(worker_seed)
    random.seed(worker_seed)


def train():
    # --- 1. åŠ è½½é…ç½® ---
    # å®é™…é¡¹ç›®ä¸­å»ºè®®ä½¿ç”¨ yaml.safe_load(open("configs/config.yaml"))
    # config = yaml.safe_load(open("../config/model_config.yaml", 'r', encoding='utf-8'))
    config = yaml.safe_load(open("/root/autodl-tmp/detection/config/model_config.yaml", 'r', encoding='utf-8'))
    seed_everything(config['seed'])
    exp_name = config.get('exp_name') or f"exp_{time.strftime('%Y%m%d_%H%M%S')}"
    os.makedirs(f"{config['save_path']}/{exp_name}", exist_ok=True)
    logger = ExperimentLogger(log_dir=f"./{config['logs_path']}", experiment_name=exp_name)
    logger.log_hyperparams(config)
    # --- 2. æ•°æ®å‡†å¤‡ ---
    # å®šä¹‰åŸºç¡€å¢å¼ºï¼ˆæ³¨æ„ï¼šä¸è¦è¿‡åº¦å¢å¼ºä»¥å…ç ´åå¾®è§‚ä¼ªå½±ï¼‰
    train_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.4814, 0.4578, 0.4082), (0.2686, 0.2613, 0.2757))  # CLIP é»˜è®¤å½’ä¸€åŒ–
    ])
    train_ds = ForensicDataset(root_dir='/root/autodl-tmp/data/train', transform=train_transform)
    # train_ds = ForensicDataset(root_dir='Z:/genimage/imagenet_ai_0419_sdv4/train', transform=train_transform)
    val_ds = ForensicDataset(root_dir='/root/autodl-tmp/data/val', transform=train_transform)
    # val_ds = ForensicDataset(root_dir='Z:/genimage/imagenet_ai_0419_sdv4/val', transform=train_transform)

    train_loader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True, num_workers=4,
                              persistent_workers=True, pin_memory=True, worker_init_fn=worker_init_fn)
    val_loader = DataLoader(val_ds, batch_size=config['batch_size'], shuffle=False, num_workers=4,
                            persistent_workers=True, pin_memory=True, worker_init_fn=worker_init_fn)

    # æˆ‘ä»¬çš„ TSF-Net
    model = TSFNet(config).to(config['device'])
    # --- 4. ä¼˜åŒ–å™¨ä¸æŸå¤±å‡½æ•° ---
    optimizer = optim.AdamW(
        filter(lambda p: p.requires_grad, model.parameters()),
        lr=config['lr'],
        weight_decay=1e-2
    )
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['epochs'])
    # --- ã€æ–°å¢ã€‘æ–­ç‚¹ç»­è®­é€»è¾‘ ---
    resume_epoch = 0  # é»˜è®¤ä¸º 0ï¼Œè¡¨ç¤ºä»å¤´è®­ç»ƒ
    resume_path = f"{config['save_path']}/model_epoch_{config['resume_epoch']}.pth"
    best_val_acc = 0.0
    # å¦‚æœæŒ‡å®šäº†è·¯å¾„ï¼Œä¸”æ–‡ä»¶å­˜åœ¨
    if config['resume_epoch'] != resume_epoch and resume_path and os.path.exists(resume_path):
        logger.log_info(f"ğŸ”„ Resuming training from {resume_path}...")
        checkpoint = torch.load(resume_path, map_location=config['device'], weights_only=True)
        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])  # éœ€è¦å…ˆå®šä¹‰ optimizer
        resume_epoch = checkpoint['epoch']
        best_val_acc = checkpoint['best_val_acc']
        logger.log_info(f"ğŸ‘‰ Successfully loaded. Resuming from Epoch {resume_epoch + 1}")

    criterion_bce = torch.nn.BCEWithLogitsLoss()
    criterion_supcon = SupConLoss(temperature=config['temp'])

    # --- 5. è®­ç»ƒå¾ªç¯ ---

    for epoch in range(resume_epoch, config['epochs']):
        model.train()
        train_loss = 0.0
        correct = 0
        total = 0

        loop = tqdm(train_loader, leave=True)
        for batch_idx, (imgs, labels) in enumerate(loop):

            imgs, labels = imgs.to(config['device']), labels.to(config['device']).float()

            # ç›´æ¥æŠŠå›¾æ‰”ç»™æ¨¡å‹ï¼Œæ¨¡å‹å†…éƒ¨ä¼šå¤„ç† CLIP (åŒ…æ‹¬ LoRA çš„æ¢¯åº¦æ›´æ–°)
            logits, z_sem, _ = model(imgs)

            # C. è®¡ç®—å¤åˆæŸå¤±
            loss_bce = criterion_bce(logits.squeeze(), labels)
            loss_sc = criterion_supcon(z_sem, labels)
            total_loss = loss_bce + config['lambda_supcon'] * loss_sc

            # D. åå‘ä¼ æ’­
            optimizer.zero_grad()
            # è®¡ç®— global_step ç”¨äº tensorboard xè½´
            global_step = epoch * len(train_loader) + batch_idx

            # æ„é€  Loss å­—å…¸ (è¿™å°±æ˜¯ç›‘æ§å¤šä»»åŠ¡å¹³è¡¡çš„å…³é”®)
            losses_dict = {
                'total': total_loss.item(),
                'bce': loss_bce.item(),
                'supcon': loss_sc.item()  # è§‚å¯Ÿè¿™ä¸ªï¼Œçœ‹èšç±»æ˜¯å¦ç”Ÿæ•ˆ
            }

            # è®°å½•
            logger.log_step(epoch, batch_idx, global_step, losses_dict)
            total_loss.backward()
            optimizer.step()
            # ç»Ÿè®¡
            train_loss += total_loss.item()
            preds = (torch.sigmoid(logits).squeeze() > 0.5).float()
            correct += (preds == labels).sum().item()
            total += labels.size(0)
            # æ”¾åœ¨ train.py çš„å¾ªç¯é‡Œ
            if batch_idx % 100 == 0:
                # 1. è·å–æ˜¾å­˜æŒ‡æ ‡ (è½¬æ¢ä¸º GB)
                mem_alloc = torch.cuda.memory_allocated() / 1024 ** 3
                mem_res = torch.cuda.memory_reserved() / 1024 ** 3
                mem_peak = torch.cuda.max_memory_allocated() / 1024 ** 3
                # 2. ã€å…³é”®ã€‘é‡ç½®å³°å€¼ç»Ÿè®¡
                # è¿™æ ·ä¸‹ä¸€æ¬¡ loop çœ‹åˆ°çš„ peak å°±æ˜¯æœªæ¥è¿™ 50 ä¸ª batch é‡Œçš„æ–°å³°å€¼
                torch.cuda.reset_peak_memory_stats()
                mem_info = f"Mem: {mem_alloc:.2f}G(A) / {mem_res:.2f}G(R) / {mem_peak:.2f}G(P)"
                logger.log_file_only(f"Epoch [{epoch + 1}] Step [{batch_idx}] Loss: {total_loss.item():.4f} | Acc: {correct / total} | {mem_info}")

            loop.set_description(f"Epoch [{epoch + 1}/{config['epochs']}]")
            loop.set_postfix(loss=total_loss.item(), acc=correct / total)

        scheduler.step()

        # --- 6. éªŒè¯ç¯èŠ‚ ---
        metrics = validate(model, val_loader, config)
        logger.log_file_only(f"Epoch {epoch + 1} Val Acc: {metrics['Acc']:.4f}")
        # è·å–å½“å‰ LR
        current_lr = optimizer.param_groups[0]['lr']

        # æ„é€  epoch çº§æŒ‡æ ‡
        train_epoch_metrics = {'loss': train_loss / len(train_loader)}  # å¯ä»¥åŠ  train_acc

        # è®°å½•æ—¥å¿— (metrics æ˜¯ validate è¿”å›çš„é‚£ä¸ªä¸°å¯Œå­—å…¸)
        logger.log_epoch(epoch + 1, train_epoch_metrics, metrics, current_lr)

        # ä¿å­˜å½“å‰ Epoch çš„æƒé‡
        current_save_path = f"{config['save_path']}/{exp_name}/model_epoch_{epoch + 1}.pth"
        # æ¨èçš„ä¿å­˜æ–¹å¼ (ä¿å­˜æ›´å¤šå…ƒæ•°æ®)
        checkpoint_dict = {
            'epoch': epoch + 1,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),  # æ¢å¤åŠ¨é‡ç­‰ä¿¡æ¯
            'best_val_acc': best_val_acc
        }
        torch.save(checkpoint_dict, current_save_path)
        # æ‰“å°ä¸€æ¡æ—¥å¿—æ–¹ä¾¿ç¡®è®¤
        logger.log_file_only(f"Saved checkpoint to {current_save_path}")
        # æ ¹æ® EER æˆ– Acc ä¿å­˜æ¨¡å‹
        if metrics['Acc'] > best_val_acc:
            best_val_acc = metrics['Acc']
            logger.log_file_only(f"ğŸ”¥ New Best Model saved with Acc: {best_val_acc:.4f} at Epoch [{epoch + 1}]")
            # torch.save(model.state_dict(), f"{config['save_path']}/best_model.pth")


def validate(model, val_loader, config):
    model.eval()

    # åˆå§‹åŒ–æŒ‡æ ‡è®¡ç®—å™¨
    evaluator = BinaryMetrics()

    with torch.no_grad():
        for imgs, labels in val_loader:
            imgs = imgs.to(config['device'])
            labels = labels.to(config['device']).float()

            logits, z_sem, _ = model(imgs)

            evaluator.update(logits.squeeze(), labels)

    # 4. è®¡ç®—å¹¶æ‰“å°æŠ¥å‘Š
    metrics = evaluator.print_report()

    # 5. (å¯é€‰) ä¿å­˜ ROC æ›²çº¿
    # evaluator.plot_roc(save_path=f"{config['save_path']}/val_roc.png")

    # è¿”å›ä¸»è¦æŒ‡æ ‡ç”¨äº Model Checkpoint (é€šå¸¸ç”¨ Accuracy æˆ– AUC)
    return metrics


if __name__ == "__main__":
    # os.environ["http_proxy"] = "http://127.0.0.1:7890"
    # os.environ["https_proxy"] = "http://127.0.0.1:7890"
    os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
    train()
