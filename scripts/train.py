import random
import numpy as np
import torch
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms
from tqdm import tqdm
import os
import yaml
import time
import sys
from PIL import Image
from io import BytesIO
from torch.amp import autocast, GradScaler

# 1. è·å–å½“å‰è„šæœ¬çš„ç»å¯¹è·¯å¾„
current_path = os.path.abspath(__file__)
# 2. è·å–å½“å‰è„šæœ¬æ‰€åœ¨çš„ç›®å½•
script_dir = os.path.dirname(current_path)
# 3. è·å–é¡¹ç›®çš„æ ¹ç›®å½•
project_root = os.path.dirname(script_dir)
# 4. å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ°ç³»ç»Ÿè·¯å¾„ä¸­
if project_root not in sys.path:
    sys.path.append(project_root)

# å¯¼å…¥ä½ ä¹‹å‰å®šä¹‰çš„æ¨¡å—
from models.tsf_net import TSFNet
from data.dataset import ForensicDataset
from losses.supcon_loss import SupConLoss
from utils.fft_utils import seed_everything
from utils.metrics import BinaryMetrics
from utils.logger import ExperimentLogger
from models.fusion import OrthogonalLoss, FineGrainedDecorrelationLoss


# --- 1. å®šä¹‰åœ¨å…¨å±€èŒƒå›´ ---
def worker_init_fn(worker_id):
    worker_seed = torch.initial_seed() % 2 ** 32
    np.random.seed(worker_seed)
    random.seed(worker_seed)


class RandomJPEGCompression(object):
    def __init__(self, quality_range=(50, 90)):
        self.quality_range = quality_range

    def __call__(self, img):
        quality = random.randint(*self.quality_range)
        output_buffer = BytesIO()
        img.save(output_buffer, format='JPEG', quality=quality)
        output_buffer.seek(0)
        return Image.open(output_buffer)


def train():
    # --- 1. åŠ è½½é…ç½® ---
    # è¯·ç¡®ä¿è·¯å¾„æ­£ç¡®
    config = yaml.safe_load(open("/root/autodl-tmp/detection/config/model_config.yaml", 'r', encoding='utf-8'))

    seed_everything(config['seed'])
    exp_name = config.get('exp_name') or f"exp_{time.strftime('%Y%m%d_%H%M%S')}_seed{config['seed']}"
    os.makedirs(f"{config['save_path']}/{exp_name}", exist_ok=True)
    logger = ExperimentLogger(log_dir=f"./{config['logs_path']}", experiment_name=exp_name)
    logger.log_hyperparams(config)

    # --- 2. æ•°æ®å‡†å¤‡ ---
    train_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomApply([
            transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 3.0))
        ], p=0.1),
        transforms.RandomApply([
            RandomJPEGCompression(quality_range=(30, 100))
        ], p=0.1),
        transforms.ToTensor(),
        transforms.Normalize((0.4814, 0.4578, 0.4082), (0.2686, 0.2613, 0.2757))
    ])

    train_ds = ForensicDataset(root_dir='/root/autodl-tmp/data/train', transform=train_transform)
    val_ds = ForensicDataset(root_dir='/root/autodl-tmp/data/val', transform=train_transform)

    train_loader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True, num_workers=4,
                              persistent_workers=True, pin_memory=True, worker_init_fn=worker_init_fn)
    val_loader = DataLoader(val_ds, batch_size=config['batch_size'], shuffle=False, num_workers=4,
                            persistent_workers=True, pin_memory=True, worker_init_fn=worker_init_fn)

    # --- 3. æ¨¡å‹åˆå§‹åŒ– ---
    model = TSFNet(config).to(config['device'])

    # --- 4. ä¼˜åŒ–å™¨ä¸æŸå¤±å‡½æ•° ---
    optimizer = optim.AdamW(
        filter(lambda p: p.requires_grad, model.parameters()),
        lr=config['lr'],
        weight_decay=1e-2
    )

    # --- ã€å…³é”®ä¿®æ”¹ Aã€‘ åˆå§‹åŒ– CosineAnnealingLR ---
    # T_max: è®¾ä¸ºæ€» Epochsï¼Œè®©å­¦ä¹ ç‡åœ¨ä¸€ä¸ªå®Œæ•´çš„è®­ç»ƒå‘¨æœŸå†…ä¸‹é™åˆ° eta_min
    # eta_min: æœ€å°å­¦ä¹ ç‡ï¼Œé˜²æ­¢é™ä¸º 0ï¼Œå»ºè®®è®¾ä¸º 1e-6
    scheduler = optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=config['epochs'],
        eta_min=1e-6
    )

    # --- æ–­ç‚¹ç»­è®­é€»è¾‘ ---
    resume_epoch = 0
    resume_path = f"{config['save_path']}/{exp_name}/model_epoch_{config['resume_epoch']}.pth"
    best_val_acc = 0.0

    if config['resume_epoch'] != resume_epoch and resume_path and os.path.exists(resume_path):
        logger.log_info(f"ğŸ”„ Resuming training from {resume_path}...")
        checkpoint = torch.load(resume_path, map_location=config['device'], weights_only=True)

        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

        # æ³¨æ„ï¼šä¸¥æ ¼æ¥è¯´ï¼Œè¿™é‡Œä¹Ÿåº”è¯¥åŠ è½½ scheduler çš„çŠ¶æ€
        if 'scheduler_state_dict' in checkpoint:
            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])

        resume_epoch = checkpoint['epoch']
        best_val_acc = checkpoint.get('best_val_acc', 0.0)
        logger.log_info(f"ğŸ‘‰ Successfully loaded. Resuming from Epoch {resume_epoch + 1}")

    # åˆå§‹åŒ–æŸå¤±å‡½æ•°
    criterion_bce = torch.nn.BCEWithLogitsLoss()
    criterion_supcon = SupConLoss(temperature=config['temp'])
    # criterion_orth = OrthogonalLoss()
    criterion_decorr = FineGrainedDecorrelationLoss()

    scaler = GradScaler('cuda')

    # --- 5. è®­ç»ƒå¾ªç¯ ---
    logger.log_info("ğŸš€ Start Training...")

    for epoch in range(resume_epoch, config['epochs']):
        model.train()
        train_loss = 0.0
        correct = 0
        total = 0

        # è·å–å½“å‰å­¦ä¹ ç‡ç”¨äºæ‰“å°
        current_lr = optimizer.param_groups[0]['lr']

        loop = tqdm(train_loader, leave=True)
        for batch_idx, (imgs, labels) in enumerate(loop):
            imgs, labels = imgs.to(config['device']), labels.to(config['device']).float()

            optimizer.zero_grad()

            with autocast('cuda'):
                # å‰å‘ä¼ æ’­
                logits, z_sem, _, f_sem_raw, v_forensic, alpha, f_tex_global, z_freq = model(imgs)

                # è®¡ç®—æŸå¤±
                loss_bce = criterion_bce(logits.squeeze(), labels)
                loss_sc = criterion_supcon(z_sem, labels)
                total_loss = loss_bce + config['lambda_supcon'] * loss_sc

                # loss_orth_val = 0.0
                loss_decorr_val = 0.0
                if config.get('fusion_type') == 'gating':
                    # loss_orth_val = criterion_orth(f_sem_raw, v_forensic)
                    # total_loss += config.get('lambda_orth', 0.1) * loss_orth_val
                    loss_decorr_val = criterion_decorr(f_sem_raw, f_tex_global, z_freq)
                    total_loss += config.get('lambda_decorr', 0.01) * loss_decorr_val

                # ---------------------------------------------------
                # ã€æ–°å¢ã€‘è®¡ç®— Gating Regularization Loss
                # ---------------------------------------------------
                loss_gate_val = 0.0
                loss_entropy = 0.0
                if config.get('fusion_type') == 'gating' and alpha is not None:
                    # # 1. è®¡ç®—å‡å€¼å’Œæ–¹å·®
                    # # alpha å½¢çŠ¶æ˜¯ [B, 1]ï¼Œå…ˆ squeeze æˆ [B]
                    # alpha_squeeze = alpha.squeeze()
                    #
                    # alpha_mean = alpha_squeeze.mean()
                    # alpha_var = alpha_squeeze.var()  # æ— åä¼°è®¡æ–¹å·®
                    #
                    # # 2. å®šä¹‰æƒé‡ (å¯ä»¥åœ¨ config é‡Œé…ï¼Œè¿™é‡Œå…ˆç¡¬ç¼–ç ç¤ºä¾‹)
                    # # Î»_var: é¼“åŠ±æ–¹å·®å¤§ (è´Ÿå·åœ¨å…¬å¼é‡Œ)
                    # # Î»_mean: é”šå®šå‡å€¼
                    # lambda_var = 0.01  # è¿™æ˜¯ä¸€ä¸ªç»éªŒå€¼ï¼Œä¸è¦å¤ªå¤§ï¼Œå¦åˆ™æ¢¯åº¦ä¼šçˆ†
                    # lambda_mean = 0.001  # "æå¼±"é”šå®š
                    #
                    # # 3. è®¡ç®—æŸå¤±
                    # # æˆ‘ä»¬å¸Œæœ› Var å˜å¤§ -> Loss å˜å° -> -Var
                    # loss_var_term = -alpha_var
                    # loss_mean_term = (alpha_mean - 0.5) ** 2
                    #
                    # loss_gate_val = lambda_var * loss_var_term + lambda_mean * loss_mean_term
                    #
                    # # åŠ å…¥æ€»æŸå¤±
                    # total_loss += config.get('lambda_gate', 0.01)* loss_gate_val

                    # 1. å–å‡º alpha [B, 1] -> [B]
                    alpha_squeeze = alpha.squeeze()

                    # 2. è®¡ç®—ç†µ (Entropy)
                    # H(p) = - [p*log(p) + (1-p)*log(1-p)]
                    # åŠ  epsilon é˜²æ­¢ log(0)
                    eps = 1e-8
                    entropy = - (alpha_squeeze * torch.log(alpha_squeeze + eps) +
                                 (1 - alpha_squeeze) * torch.log(1 - alpha_squeeze + eps))

                    # 3. è®¡ç®— Loss = - mean(Entropy)
                    # æˆ‘ä»¬å¸Œæœ› Entropy æœ€å¤§ -> Loss æœ€å°
                    loss_entropy = - entropy.mean()

                    # 4. åŠ æƒ
                    # å»ºè®®æƒé‡ï¼š0.01 ~ 0.1ï¼Œå¦‚æœ Alpha ä¾ç„¶å¡åœ¨ 0.9ï¼Œå°±åŠ å¤§åˆ° 0.1
                    # åŠ å…¥æ€» Loss
                    total_loss += config.get('lambda_entropy', 0.001) * loss_entropy

            # åå‘ä¼ æ’­ä¸æ›´æ–°
            scaler.scale(total_loss).backward()
            scaler.step(optimizer)
            scaler.update()

            # ä¸ºäº†é˜²æ­¢å˜é‡æœªå®šä¹‰ï¼Œå…ˆè·å–æ•°å€¼ï¼ˆå®‰å…¨è·å–ï¼‰
            val_bce = loss_bce.item()
            val_sc  = loss_sc.item()
            # val_orth = loss_orth_val.item() if isinstance(loss_orth_val, torch.Tensor) else 0.0
            val_decorr = loss_decorr_val.item() if isinstance(loss_decorr_val, torch.Tensor) else 0.0
            val_ent  = loss_entropy.item() if 'loss_entropy' in locals() and isinstance(loss_entropy, torch.Tensor) else 0.0

            # è®°å½•æ—¥å¿—
            global_step = epoch * len(train_loader) + batch_idx
            losses_dict = {
                'total': total_loss.item(),
                'bce': val_bce,
                'supcon': val_sc,
                'decorr': val_decorr,
                'entropy': val_ent,
            }
            logger.log_step(epoch, batch_idx, global_step, losses_dict)

            # ç»Ÿè®¡æŒ‡æ ‡
            train_loss += total_loss.item()
            preds = (torch.sigmoid(logits).squeeze() > 0.5).float()
            correct += (preds == labels).sum().item()
            total += labels.size(0)

            # æ˜¾å­˜ç›‘æ§ä¸æ‰“å°
            if batch_idx % 100 == 0:
                mem_alloc = torch.cuda.memory_allocated() / 1024 ** 3
                mem_res = torch.cuda.memory_reserved() / 1024 ** 3
                mem_peak = torch.cuda.max_memory_allocated() / 1024 ** 3
                torch.cuda.reset_peak_memory_stats()
                mem_info = f"Mem: {mem_alloc:.2f}G(A) / {mem_res:.2f}G(R) / {mem_peak:.2f}G(P)"
                # è¿™é‡ŒåŠ å…¥äº† LR çš„æ‰“å°
                loss_detail = f"Loss: {total_loss.item():.4f} [BCE:{val_bce:.4f} SC:{val_sc:.4f}"
                # å¦‚æœæœ‰ gating ç›¸å…³çš„æŸå¤±ï¼Œä¹Ÿæ‰“å°å‡ºæ¥
                if config.get('fusion_type') == 'gating':
                    loss_detail += f" Decorr:{val_decorr:.4f} Ent:{val_ent:.4f}"
                loss_detail += "]"
                logger.log_file_only(
                    f"Epoch [{epoch + 1}] Step [{batch_idx}] LR: {current_lr:.6f} | {loss_detail} | Acc: {correct / total:.4f} | {mem_info}"
                )

            loop.set_description(f"Epoch [{epoch + 1}/{config['epochs']}]")
            loop.set_postfix(loss=total_loss.item(), acc=correct / total, lr=current_lr)

        # --- ã€å…³é”®ä¿®æ”¹ Bã€‘ åœ¨ Epoch ç»“æŸæ—¶æ›´æ–°å­¦ä¹ ç‡ ---
        scheduler.step()

        # --- 6. éªŒè¯ç¯èŠ‚ ---
        metrics = validate(model, val_loader, config)
        logger.log_file_only(f"Epoch {epoch + 1} Val Acc: {metrics['Acc']:.4f}")

        # è®°å½• Epoch çº§æŒ‡æ ‡
        train_epoch_metrics = {'loss': train_loss / len(train_loader)}
        logger.log_epoch(epoch + 1, train_epoch_metrics, metrics, current_lr)

        # ä¿å­˜æ¨¡å‹
        current_save_path = f"{config['save_path']}/{exp_name}/model_epoch_{epoch + 1}.pth"
        checkpoint_dict = {
            'epoch': epoch + 1,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'scheduler_state_dict': scheduler.state_dict(),  # å»ºè®®åŠ å…¥è¿™ä¸ª
            'best_val_acc': best_val_acc
        }
        torch.save(checkpoint_dict, current_save_path)
        logger.log_file_only(f"Saved checkpoint to {current_save_path}")

        if metrics['Acc'] > best_val_acc:
            best_val_acc = metrics['Acc']
            logger.log_file_only(f"ğŸ”¥ New Best Model saved with Acc: {best_val_acc:.4f} at Epoch [{epoch + 1}]")


def validate(model, val_loader, config):
    model.eval()
    evaluator = BinaryMetrics()
    with torch.no_grad():
        for imgs, labels in val_loader:
            imgs = imgs.to(config['device'])
            labels = labels.to(config['device']).float()
            # è¿™é‡Œçš„ _ å ä½ç¬¦æ•°é‡è¦æ ¹æ®ä½ çš„æ¨¡å‹è¿”å›å€¼åŒ¹é…ï¼Œè¿™é‡Œå‡è®¾æ˜¯ 5 ä¸ª
            logits, z_sem, _, _, _, _, _, _ = model(imgs)
            evaluator.update(logits.squeeze(), labels)
    return evaluator.print_report()


if __name__ == "__main__":
    os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
    train()
